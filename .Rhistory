data.rank <-rank(data.all)
Women.data.rank.sum <-sum(data.rank[data.all == Women.data ])
Men.data.rank.sum <-sum(data.rank[data.all == Men.data])
min.rank.sum <-sum(data.rank[data.all == Minorities.data])
kruskal.test(data.all ~ factor, data = airquality)
Women.data <- c(23, 41, 54, 66, 78)
Men.data <- c(45, 55, 60, 70, 72)
Minorities.data <- c(18, 30, 34, 40, 44)
data.all <- c(Women.data , Men.data, Minorities.data)
factor <- (rep(c(1, 2, 5), each =5))
df.data <- data.frame(factor, data.all)
n <- length(data.all)
data.rank <-rank(data.all)
Women.data.rank.sum <-sum(data.rank[data.all == Women.data ])
Men.data.rank.sum <-sum(data.rank[data.all == Men.data])
min.rank.sum <-sum(data.rank[data.all == Minorities.data])
a <- 12/(n*(n+1))
t1 <- (Men.data.rank.sum*Men.data.rank.sum)/length(Men.data)
t2 <- (Women.data .rank.sum*Women.data .rank.sum)/length(Women.data )
t3 <- (min.rank.sum *min.rank.sum) /length(Minorities.data)
b <- 3*(n +1)
H <- a* (t1 + t2 + t3) - b
t1 <- (Men.data.rank.sum*Men.data.rank.sum)/length(Men.data)
t2 <- (Women.data .rank.sum*Women.data .rank.sum)/length(Women.data )
Women.data <- c(23, 41, 54, 66, 78)
Men.data <- c(45, 55, 60, 70, 72)
Minorities.data <- c(18, 30, 34, 40, 44)
data.all <- c(Women.data , Men.data, Minorities.data)
factor <- (rep(c(1, 2, 5), each =5))
df.data <- data.frame(factor, data.all)
n <- length(data.all)
data.rank <-rank(data.all)
Women.data.rank.sum <-sum(data.rank[data.all == Women.data ])
Men.data.rank.sum <-sum(data.rank[data.all == Men.data])
min.rank.sum <-sum(data.rank[data.all == Minorities.data])
a <- 12/(n*(n+1))
t1 <- (Men.data.rank.sum*Men.data.rank.sum)/length(Men.data)
t2 <- (Women.data.rank.sum*Women.data .rank.sum)/length(Women.data )
t3 <- (min.rank.sum *min.rank.sum) /length(Minorities.data)
b <- 3*(n +1)
H <- a* (t1 + t2 + t3) - b
H
Women.data <- c(23, 41, 54, 66, 78)
Men.data <- c(45, 55, 60, 70, 72)
Minorities.data <- c(18, 30, 34, 40, 44)
data.all <- c(Women.data , Men.data, Minorities.data)
factor <- (rep(c(1, 2, 5), each =5))
df.data <- data.frame(factor, data.all)
n <- length(data.all)
data.rank <-rank(data.all)
Women.data.rank.sum <-sum(data.rank[data.all == Women.data ])
Men.data.rank.sum <-sum(data.rank[data.all == Men.data])
min.rank.sum <-sum(data.rank[data.all == Minorities.data])
a <- 12/(n*(n+1))
t1 <- (Men.data.rank.sum*Men.data.rank.sum)/length(Men.data)
t2 <- (Women.data.rank.sum*Women.data rank.sum)/length(Women.data )
t3 <- (min.rank.sum *min.rank.sum) /length(Minorities.data)
b <- 3*(n +1)
H <- a* (t1 + t2 + t3) - b
H
Women.data <- c(23, 41, 54, 66, 78)
Men.data <- c(45, 55, 60, 70, 72)
Minorities.data <- c(18, 30, 34, 40, 44)
data.all <- c(Women.data , Men.data, Minorities.data)
factor <- (rep(c(1, 2, 5), each =5))
df.data <- data.frame(factor, data.all)
n <- length(data.all)
data.rank <-rank(data.all)
Women.data.rank.sum <-sum(data.rank[data.all == Women.data ])
Men.data.rank.sum <-sum(data.rank[data.all == Men.data])
min.rank.sum <-sum(data.rank[data.all == Minorities.data])
a <- 12/(n*(n+1))
t1 <- (Men.data.rank.sum*Men.data.rank.sum)/length(Men.data)
t2 <- (Women.data.rank.sum*Women.data.rank.sum)/length(Women.data )
t3 <- (min.rank.sum *min.rank.sum) /length(Minorities.data)
b <- 3*(n +1)
H <- a* (t1 + t2 + t3) - b
H
# Q1:
df.data <-airquality
head(df.data)
data.all <- df.data$Ozone
data.rank <-rank(data.all)
n <- length(df.data$Ozone)
may <-sum(data.rank[df.data$Month==5])
june <-sum(data.rank[df.data$Month==6])
july <-sum(data.rank[df.data$Month==7])
aug <- sum(data.rank[df.data$Month==8])
sep <-sum(data.rank[df.data$Month==9])
n1 <- sum(df.data$Month==5)
n2 <- sum(df.data$Month==6)
n3 <- sum(df.data$Month==7)
n4 <- sum(df.data$Month==8)
n5 <- sum(df.data$Month==9)
a <- 12/(n*(n+1))
t1 <- (may*may)/n1
t2 <- (june*june)/n2
t3 <- (july*july)/n3
t4 <- (aug*aug)/n4
t5 <- (sep*sep)/n5
b <- 3*(n +1)
H <- a*(t1 + t2 + t3 + t4 + t5) - b
H
Women.data <- c(23, 41, 54, 66, 78)
Men.data <- c(45, 55, 60, 70, 72)
Minorities.data <- c(18, 30, 34, 40, 44)
data.all <- c(Women.data , Men.data, Minorities.data)
factor <- (rep(c(1, 2, 5), each =5))
df.data <- data.frame(factor, data.all)
n <- length(data.all)
data.rank <-rank(data.all)
Women.data.rank.sum <-sum(data.rank[data.all == Women.data ])
Men.data.rank.sum <-sum(data.rank[data.all == Men.data])
min.rank.sum <-sum(data.rank[data.all == Minorities.data])
a <- 12/(n*(n+1))
t1 <- (Men.data.rank.sum*Men.data.rank.sum)/length(Men.data)
t2 <- (Women.data.rank.sum*Women.data.rank.sum)/length(Women.data )
t3 <- (min.rank.sum *min.rank.sum) /length(Minorities.data)
b <- 3*(n +1)
H <-
Women.data <- c(23, 41, 54, 66, 78)
Men.data <- c(45, 55, 60, 70, 72)
Minorities.data <- c(18, 30, 34, 40, 44)
data.all <- c(Women.data , Men.data, Minorities.data)
factor <- (rep(c(1, 2, 5), each =5))
df.data <- data.frame(factor, data.all)
n <- length(data.all)
data.rank <-rank(data.all)
Women.data.rank.sum <-sum(data.rank[data.all == Women.data ])
Men.data.rank.sum <-sum(data.rank[data.all == Men.data])
min.rank.sum <-sum(data.rank[data.all == Minorities.data])
a <- 12/(n*(n+1))
t1 <- (Men.data.rank.sum*Men.data.rank.sum)/length(Men.data)
t2 <- (Women.data.rank.sum*Women.data.rank.sum)/length(Women.data )
t3 <- (min.rank.sum *min.rank.sum) /length(Minorities.data)
b <- 3*(n +1)
H <- a* (t1 + t2 + t3) - b
H
H <- (12/(15*(15+1)) )* ( (44*44)/5 + (56*56)/5 + (20*20)/5 ) - 3 * (15+1)
H
English = c(56,	75,	45,	71,	62,	64,	58,	80,	76,	61)
Math    = c(66, 70, 40, 60, 65, 56, 59, 77, 67, 63)
plot(density(English)) #not normal
plot(density(Math)) #not normal
plot(density(Math)) #not normal
plot(density(English)) #not normal
plot(density(Math)) #not normal
plot(density(English)) #not normal
plot(density(Math)) #not normal
#Not normal, so use Spearman
data.all<- c(English, Math)
rank.english <
data.all
rank.all <-rank(data.all)
rank.english <-rank.all[data.all == English]
data.all<- c(English, Math)
rank.all <-rank(data.all)
rank.english <-rank.all[data.all == English]
rank.Math <-rank.all[data.all == Math]
plot(density(English)) #not normal
plot(density(Math)) #not normal
#Not normal, so use Spearman
data.all<- c(English, Math)
rank.all <-rank(data.all)
rank.english <-rank.all[data.all == English]
rank.Math <-rank.all[data.all == Math]
cor(rank.english,rank.Math)
cor.test(English, Math, method = "spearman")
Sxy <- English %*% Math
n<-length(data.all)
Sxy <- English %*% Math ((sum(English)*sum(math))/n)
Sxy <- English %*% Math*((sum(English)*sum(math))/n)
English = c(56,	75,	45,	71,	62,	64,	58,	80,	76,	61)
Math    = c(66, 70, 40, 60, 65, 56, 59, 77, 67, 63)
plot(density(English)) #not normal
plot(density(Math)) #not normal
#Not normal, so use Spearman
data.all<- c(English, Math)
rank.all <-rank(data.all)
rank.english <-rank.all[data.all == English]
rank.Math <-rank.all[data.all == Math]
n<-length(data.all)
Sxy <- English %*% Math*((sum(English)*sum(math))/n)
English %*% Math
as.numeric(English %*% Math)
Sxy <- as.numeric(English %*% Math) *((sum(English)*sum(math))/n)
Sxy <- as.numeric(English %*% Math) *((sum(English)*sum(Math))/n)
n.math <-length(Math)
n.english <- length(Engish)
Sxy <- as.numeric(English %*% Math) - ((sum(English)*sum(Math))/n)
Sxx <- as.numeric(English %*% English) *((sum(English)*sum(Math))/n.english)
n <- length(data.all)
n.math <-length(Math)
n.english <- length(English)
Sxx <- as.numeric(English %*% English) *((sum(English)*sum(Math))/n.english)
Sxy <- as.numeric(English %*% Math) - ((sum(English)*sum(Math))/n)
Sxx <- as.numeric(English %*% English) *((sum(English)*sum(English))/n.english)
Syy <- as.numeric(Math %*% Math) *((sum(Math)*sum(Math))/n.math)
Sxy <- as.numeric(English %*% Math) - ((sum(English)*sum(Math))/n)
Sxx <- as.numeric(English %*% English) *((sum(English)*sum(English))/n.english)
Syy <- as.numeric(Math %*% Math) *((sum(Math)*sum(Math))/n.math)
r.pearson <- Sxy/(sqrt(Sxx*Syy))
r.pearson
Sxy
Sxx
Syy
Sxy <- as.numeric(English %*% Math) - ((sum(English)*sum(Math))/n)
Sxx <- as.numeric(English %*% English) - ((sum(English)*sum(English))/n.english)
Syy <- as.numeric(Math %*% Math) - ((sum(Math)*sum(Math))/n.math)
r.pearson <- Sxy/(sqrt(Sxx*Syy))
r.pearson
English = c(56,	75,	45,	71,	62,	64,	58,	80,	76,	61)
Math = c(66, 70, 40, 60, 65, 56, 59, 77, 67, 63)
plot(density(English)) #not normal
plot(density(Math)) #not normal
#Not normal, so use Spearman
data.all<- c(English, Math)
rank.all <-rank(data.all)
rank.english <-rank.all[data.all == English]
rank.Math <-rank.all[data.all == Math]
n <- length(data.all)
n.math <-length(Math)
n.english <- length(English)
Sxy <- as.numeric(English %*% Math) - ((sum(English)*sum(Math))/n)
Sxx <- as.numeric(English %*% English) - ((sum(English)*sum(English))/n.english)
Syy <- as.numeric(Math %*% Math) - ((sum(Math)*sum(Math))/n.math)
r.spearman <- Sxy/(sqrt(Sxx*Syy))
r.spearman
cor(rank.english,rank.Math)
cor.test(English, Math, method = "spearman")
setwd("~/R/Data Analytics")
unqie(data.all)
unique(data.all)
length(unique(data.all)) == length(data.all)
unique(data.all) == data.all
r.spearman <- Sxy/(sqrt(Sxx*Syy))
r.spearman
cor.test(English, Math, method = "spearman")
r.spearman
r.spearman <- cov(rank.english, rank.Math)/sqrt(var(English)*var(Math))
r.spearman
Sxy <- as.numeric((English - mean(English)) %*% (Math-mean(Math))) - ((sum(English)*sum(Math))/n)
Math-mean(Math)
(English - mean(English)
)
Sxy <- as.numeric((English - mean(English)) %*% (Math-mean(Math)))
Sxy <- as.numeric((English - mean(English)) %*% (Math-mean(Math)))
Sxx <- as.numeric((English - mean(English)) %*% (English - mean(English)))
Syy <- as.numeric((Math-mean(Math)) %*% (Math-mean(Math)))
English = c(56,	75,	45,	71,	62,	64,	58,	80,	76,	61)
Math = c(66, 70, 40, 60, 65, 56, 59, 77, 67, 63)
plot(density(English)) #not normal
plot(density(Math)) #not normal
#Not normal, so use Spearman
data.all<- c(English, Math)
rank.all <-rank(data.all)
rank.english <-rank.all[data.all == English]
rank.Math <-rank.all[data.all == Math]
n <- length(data.all)
n.math <-length(Math)
n.english <- length(English)
Sxy <- as.numeric((English - mean(English)) %*% (Math-mean(Math)))
Sxx <- as.numeric((English - mean(English)) %*% (English - mean(English)))
Syy <- as.numeric((Math-mean(Math)) %*% (Math-mean(Math)))
r.spearman <- Sxy/(sqrt(Sxx*Syy))
r
Syy <- as.numeric((Math-mean(Math)) %*% (Math-mean(Math)))
r.spearman
r.spearman <- cov(rank.english, rank.Math)/sqrt(var(English)*var(Math))
r.spearman
cor(rank.english,rank.Math)
cor.test(English, Math, method = "spearman")
library(readr)
dataset <- read_csv(NULL)
View(dataset)
#Question 3
yelp.data <- read.csv(yelp_lab8.csv)
#Question 3
yelp.data <- read.csv(file = "yelp_lab8.csv")
View(head(yelp.data))
sum(yelp.data$stars > 1)
train.stars <- yelp.data$stars
yelp.stars <- yelp.data$stars
View(head(yelp.data))
yelp.stars
yelp.response <- yelp.data[2,]
yelp.factors <- yelp.data[-2,]
View(sample(1:nrow(yelp.data), 0.7*:nrow(yelp.data)))
train.index <-sample(1:nrow(yelp.data), 0.7*nrow(yelp.data))
View(sample(1:nrow(yelp.data), 0.7*nrow(yelp.data)))
train.factors <- yelp.factors[train.index,]
test.factors <- yelp.factors[-train.index,]
yelp.data <- read.csv(file = "yelp_lab8.csv")
View(head(yelp.data))
yelp.response <- yelp.data[2,]
yelp.factors <- yelp.data[-2,]
train.index <-sample(1:nrow(yelp.data), 0.7*nrow(yelp.data))
train.factors <- yelp.factors[train.index,]
test.factors <- yelp.factors[-train.index,]
train.factors <- yelp.response[train.index,]
test.factors <- yelp.response[-train.index,]
#Question 3
yelp.data <- read.csv(file = "yelp_lab8.csv")
View(head(yelp.data))
train.index <-sample(1:nrow(yelp.data), 0.7*nrow(yelp.data))
data.train <- yelp.data[train.index,]
data.test <- yelp.data[-train.index,]
str(data.train)
glm_model <-glm(stars~., family = binomial(link = 'logit'), data = data.train)
summary(glm_model)
model <- glm( ~.,family=binomial, data=train)
glm_model <-glm(stars~., family = binomial, data = data.train)
summary(glm_model)
yelp_reduced <- read.csv(file = "yelp_lab8.csv")
train_index <- sample(1:nrow(yelp_reduced), 0.7 * nrow(yelp_reduced))
train.set <- yelp_reduced[train_index,]
test.set  <- yelp_reduced[-train_index,]
# Now, we remove the stars column from our training and test datasets.
train.set_new <- train.set[-2]
test.set_new <- test.set[-2]
# Now, we store the labels from our training and test datasets.
stars_train_labels <- train.set$stars
stars_test_labels <- test.set$stars
glm_model <- glm(stars~.,train.set, family = "binomial")
summary(glm_model)
#Question 3
yelp.data <- read.csv(file = "yelp_lab8.csv")
View(head(yelp.data))
train.index <-sample(1:nrow(yelp.data), 0.7*nrow(yelp.data))
data.train <- yelp.data[train.index,]
data.test <- yelp.data[-train.index,]
train.factors <- yelp.response[train.index,]
test.factors <- yelp.response[-train.index,]
glm_model <-glm(stars~., family = binomial, data = data.train)
summary(glm_model)
summary(glm_model)$coeff
View(summary(glm_model)$coeff)
summary(glm_model)$coeff$Estimate
summary(glm_model)$Estimate
coef(summary(glm_model))["a2","Pr(>|t|)"]
coef(summary(glm_model))[,"Pr(>|t|)"]
names(summary(glm_model))
coef(summary(glm_model))[,"Pr(>|z|)"]
View(coef(summary(glm_model))[,"Pr(>|z|)"])
coef(summary(glm_model))[,"Pr(>|z|)"]
dim(coef(summary(glm_model))[,"Pr(>|z|)"])
dim(coef(summary(glm_model))[,"Estimate"])
coef(summary(glm_model))[,"Estimate"]
str(coef(summary(glm_model))[,"Estimate"])
factors <- names(coef(summary(glm_model))[,"Estimate"])
factors
coefficients <- *(coef(summary(glm_model))[,"Estimate"])
coefficients <- (coef(summary(glm_model))[,"Estimate"])[,1]
dim((coef(summary(glm_model))[,"Estimate"]))
predict(glm_model, newdata = data.frame(city ="Toronto", review_count = 200, categories = categoriesCoffee or Sandwiches) type = "response")  )
predict(glm_model, newdata = data.frame(city ="Toronto", review_count = 200, categories = "Coffee or Sandwiches") type = "response")  )
predict(glm_model, newdata = data.frame(city ="Toronto", review_count = 200, categories = "Coffee or Sandwiches"), type = "response")  )
predict(glm_model, newdata = data.frame(city ="Toronto", review_count = 200, categories = "Coffee or Sandwiches"), type = "response")
train.response <- yelp.response[train.index,]
test.response <- yelp.response[-train.index,]
yelp.data <- read.csv(file = "yelp_lab8.csv")
View(head(yelp.data))
train.index <-sample(1:nrow(yelp.data), 0.7*nrow(yelp.data))
data.train <- yelp.data[train.index,]
data.test <- yelp.data[-train.index,]
yelp.data <- read.csv(file = "yelp_lab8.csv")
train.index <-sample(1:nrow(yelp.data), 0.7*nrow(yelp.data))
data.train <- yelp.data[train.index,]
data.test <- yelp.data[-train.index,]
train.factors <- yelp.response[train.index,]
test.factors <- yelp.response[-train.index,]
#Question 3
yelp.data <- read.csv(file = "yelp_lab8.csv")
train.index <-sample(1:nrow(yelp.data), 0.7*nrow(yelp.data))
data.train <- yelp.data[train.index,]
data.test <- yelp.data[-train.index,]
glm_model <-glm(stars~., family = binomial, data = data.train)
summary(glm_model)
glm_model <- glm(stars~.,train.set, family = "binomial")
predict(glm_model, newdata = data.frame(city ="Toronto", review_count = 200, categories = "Coffee or Sandwiches"), type = "response")
# Let's split the yelp dataset into training and test set.
yelp_reduced <- read.csv(file = "yelp_lab8.csv")
train_index <- sample(1:nrow(yelp_reduced), 0.7 * nrow(yelp_reduced))
train.set <- yelp_reduced[train_index,]
test.set  <- yelp_reduced[-train_index,]
# Now, we remove the stars column from our training and test datasets.
train.set_new <- train.set[-2]
test.set_new <- test.set[-2]
# Now, we store the labels from our training and test datasets.
stars_train_labels <- train.set$stars
stars_test_labels <- test.set$stars
glm_model <- glm(stars~.,train.set, family = "binomial")
summary(glm_model)
predict(glm_model, newdata=data.frame(city="Toronto", review_count=200, categories="Coffee or Sandwiches"), type="response")
yelp.data <- read.csv(file = "yelp_lab8.csv")
train.index <-sample(1:nrow(yelp.data), 0.7*nrow(yelp.data))
data.train <- yelp.data[train.index,]
data.test <- yelp.data[-train.index,]
glm_model <-glm(stars~., family = "binomial", data = data.train)
summary(glm_model)
predict(glm_model, newdata = data.frame(city ="Toronto", review_count = 200, categories = "Coffee or Sandwiches"), type = "response")
data.test.response <-data.train[,2]
data.test.factors <-data.train[,-2]
data.test.response <-data.train[,2]
predicted <- predict(glm_model, data.test.factors, type = "response")
View(predicted)
head(View(predicted))
predicted_V1 <- ifelse(predicted>=0.5, 1, 0)
View(table(actual = data.test.response, predicted = predicted_V1))
confusionMatrix_V1 <- table(actual = data.test.response, predicted = predicted_V1)
sum(diag(confusionMatrix_V1))/nrow(test.set)
# Let's split the yelp dataset into training and test set.
yelp_reduced <- read.csv(file = "yelp_lab8.csv")
train_index <- sample(1:nrow(yelp_reduced), 0.7 * nrow(yelp_reduced))
train.set <- yelp_reduced[train_index,]
test.set  <- yelp_reduced[-train_index,]
# Now, we remove the stars column from our training and test datasets.
train.set_new <- train.set[-2]
test.set_new <- test.set[-2]
# Now, we store the labels from our training and test datasets.
stars_train_labels <- train.set$stars
stars_test_labels <- test.set$stars
glm_model <- glm(stars~.,train.set, family = "binomial")
summary(glm_model)
predict(glm_model, newdata=data.frame(city="Toronto", review_count=200, categories="Coffee or Sandwiches"), type="response")
predicted_V1 <- ifelse(predicted>=0.5, 1, 0)
confusionMatrix_V1 <- table(actual = test.set$stars, predicted = predicted_V1)
sum(diag(confusionMatrix_V1))/nrow(test.set)
#Question 3
yelp.data <- read.csv(file = "yelp_lab8.csv")
train.index <-sample(1:nrow(yelp.data), 0.7*nrow(yelp.data))
data.train <- yelp.data[train.index,]
data.test <- yelp.data[-train.index,]
data.test.factors <-data.train[,-2]
data.test.response <-data.train[,2]
glm_model <-glm(stars~., family = "binomial", data = data.train)
summary(glm_model)
# # Let's split the yelp dataset into training and test set.
#
# yelp_reduced <- read.csv(file = "yelp_lab8.csv")
#
# train_index <- sample(1:nrow(yelp_reduced), 0.7 * nrow(yelp_reduced))
# train.set <- yelp_reduced[train_index,]
# test.set  <- yelp_reduced[-train_index,]
#
# # Now, we remove the stars column from our training and test datasets.
#
# train.set_new <- train.set[-2]
# test.set_new <- test.set[-2]
#
# # Now, we store the labels from our training and test datasets.
#
# stars_train_labels <- train.set$stars
# stars_test_labels <- test.set$stars
#
# glm_model <- glm(stars~.,train.set, family = "binomial")
# summary(glm_model)
#
# predict(glm_model, newdata=data.frame(city="Toronto", review_count=200, categories="Coffee or Sandwiches"), type="response")
#
# predicted_V1 <- ifelse(predicted>=0.5, 1, 0)
# confusionMatrix_V1 <- table(actual = test.set$stars, predicted = predicted_V1)
# sum(diag(confusionMatrix_V1))/nrow(test.set)
predict(glm_model, newdata = data.frame(city ="Toronto", review_count = 200, categories = "Coffee or Sandwiches"), type = "response")
predicted <- predict(glm_model, data.test.factors, type = "response")
head(View(predicted))
predicted_V1 <- ifelse(predicted>=0.5, 1, 0)
confusionMatrix_V1 <- table(actual = data.test.response, predicted = predicted_V1)
sum(diag(confusionMatrix_V1))/nrow(test.set)
#Question 3
yelp.data <- read.csv(file = "yelp_lab8.csv")
train.index <-sample(1:nrow(yelp.data), 0.7*nrow(yelp.data))
data.train <- yelp.data[train.index,]
data.test <- yelp.data[-train.index,]
data.test.factors <-data.train[,-2]
data.test.response <-data.train[,2]
glm_model <-glm(stars~., family = "binomial", data = data.train)
summary(glm_model)
# # Let's split the yelp dataset into training and test set.
#
# yelp_reduced <- read.csv(file = "yelp_lab8.csv")
#
# train_index <- sample(1:nrow(yelp_reduced), 0.7 * nrow(yelp_reduced))
# train.set <- yelp_reduced[train_index,]
# test.set  <- yelp_reduced[-train_index,]
#
# # Now, we remove the stars column from our training and test datasets.
#
# train.set_new <- train.set[-2]
# test.set_new <- test.set[-2]
#
# # Now, we store the labels from our training and test datasets.
#
# stars_train_labels <- train.set$stars
# stars_test_labels <- test.set$stars
#
# glm_model <- glm(stars~.,train.set, family = "binomial")
# summary(glm_model)
#
# predict(glm_model, newdata=data.frame(city="Toronto", review_count=200, categories="Coffee or Sandwiches"), type="response")
#
# predicted_V1 <- ifelse(predicted>=0.5, 1, 0)
# confusionMatrix_V1 <- table(actual = test.set$stars, predicted = predicted_V1)
# sum(diag(confusionMatrix_V1))/nrow(test.set)
predict(glm_model, newdata = data.frame(city ="Toronto", review_count = 200, categories = "Coffee or Sandwiches"), type = "response")
predicted <- predict(glm_model, data.test.factors, type = "response")
head(View(predicted))
predicted_V1 <- ifelse(predicted>=0.5, 1, 0)
confusionMatrix_V1 <- table(actual = data.test.response, predicted = predicted_V1)
sum(diag(confusionMatrix_V1))/nrow(data.test)
View(diag(confusionMatrix_V1))
View(confusionMatrix_V1)
